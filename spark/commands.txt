spark = SparkSession.builder.getOrCreate()

//feed data to create
df1 = spark.read.format("csv").load("/home/jorge_cruz7/spark/escuelasPR.csv")

df2 = spark.read.format("csv").load("/home/jorge_cruz7/spark/studentsPR.csv")

//rename column
df11 = df1.toDF("regionEducativa","distritoEscolar ","municipio","Escuela_ID","Escuela_Nombre","nivel","CollegeBoard_ID ")

df22 = df2.toDF("region","distrito","eid","nombreEscuela","nivel","sexo","sid")

//------join ----------

exersice 1)
df11.join(df22,'eid').filter(df11.nivel == "Superior").filter(df22.sexo == "M").filter((df11.municipio == "Ponce") | (df11.municipio == "San Juan")).show()

exersice 2)

df11.filter(df11.regionEducativa == "Arecibo").groupBy(df11.distritoEscolar, df11.municipio).count().
show()
